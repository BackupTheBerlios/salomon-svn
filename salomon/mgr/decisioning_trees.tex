\section{Drzewa decyzyjne}
\label{lab:dec_trees}

%System na obecnym etapie jego rozwoju pozwala na uruchamianie algorytmów
%wykorzystuj¹cych drzewa decyzyjne, dlatego te¿ im chcielibyœmy poœwiêciæ nieco
%wiêcej miejsca.

% http://www.dbmsmag.com/9807m05.html
% When a businessperson needs to make a decision based on several factors, a
% decision tree can help identify which factors to consider and how each factor
% has historically been associated with different outcomes of the decision. For
% example, in our credit risk case study (See the sidebar Predicting Credit Risk),
% we have data for each applicantýs debt, income, and marital status. A decision
% tree creates a model as either a graphical tree or a set of text rules that can
% predict (classify) each applicant as a good or bad credit risk.

%Kiedy biznesmen potrzebuje podj¹æ decyzje bazuj¹c na kilku wspó³czynnikach,
%drzewa decyzyjne mog¹ pomoc w wybraniu odpowiednich wspó³czynników oraz 
%opowiedzieæ jak dany wspó³czynnik w przesz³oœci wp³ywa³ na decyzje.
%Przyk³adowo, podczas obliczania ryzyka kredytowego, posiadamy dla ka¿dego
%potencjalnego kredytobiorcy dane o jego kredytach, przychodach oraz jego
%statusie materialnym. Drzewa decyzyjne tworz¹ zarówno drzewo w postaci
%graficznej, jak zbiór regu³ tekstowych, dziêki którym mo¿emy okreœliæ,
%czy dana aplikacja jest obarczona du¿ym lub ma³ym ryzykiem kredytowym.

% A decision tree is a model that is both predictive and descriptive. It is called
% a decision tree because the resulting model is presented in the form of a tree
% structure. (See Figure 1.) The visual presentation makes the decision tree model
% very easy to understand and assimilate. As a result, the decision tree has
% become a very popular data mining technique. Decision trees are most commonly
% used for classification (predicting what group a case belongs to), but can also
% be used for regression (predicting a specific value).

Drzewa decyzyjne to jeden z przyk³adów reprezentacji wiedzy uzyskanej
za pomoc¹ algorytmów uczenia maszynowego.

Drzewo decyzyjne jest modelem zarówno predyktywnym jak i opisowym.
%!!!predictive and descriptive!!!.
Nazywany jest drzewem decyzyjnym, poniewa¿ prezentowany jest w formie
struktury drzewiastej~\ref{fig:sample_tree}. Graficzna reprezentacja powoduje,
¿e zrozumienie go, czy te¿ porównanie z innym drzewem jest proste nawet dla cz³owieka. 
Drzewa decyzyjne sta³y siê bardzo popularne w technikach data maning-u (\ref{lab:data_mining}). 
S¹ one najpowszechniej u¿ywane do klasyfikacji (predykuj¹ do której grupy nale¿y dany
przypadek), lecz mog¹ byæ równie¿ u¿ywane przy regresji (predykuj¹ wartoœæ).

% The decision tree method encompasses a number of specific algorithms, including
% Classification and Regression Trees (CART), Chi-squared Automatic Interaction
% Detection (CHAID), C4.5 and C5.0 (from work by J. Ross Quinlan of Rulequest
% Research Pty Ltd, in St. Ives, Australia, www.rulequest.com).

Metody drzew decyzyjnych obejmuj¹ wiele algorytmów. Miêdzy innymi drzewa
klasyfikuj¹ce i regresyjne (ang. \emph{Classification and Regression Trees
(CART)}), \emph{Chi-squared Automatic
Interaction Detection (CHAID)}, \emph{C4.5} and \emph{C5.0}.

% Decision trees graphically display the relationships found in data. Most
% products also translate the tree-to-text rules such as If Income = High and
% Years on job > 5 Then Credit risk = Good. In fact, decision tree algorithms are
% very similar to rule induction algorithms which produce rule sets without a
% decision tree.

Drzewa decyzyjne w graficzny sposób obrazuj¹ zale¿noœci wystêpuj¹ce w danych.
Mo¿na je równie¿ przedstawiaæ w postaci regu³ tekstowych np.
\\
\\
\emph{Jeœli Dochód = Wysoki i Lata Pracy $>$ 5 Wtedy Ryzyko kredytowe = Ma³e}.
\\
\\
Algorytmy drzew decyzyjnych s¹ bardzo podobne do algorytmów indukcji regu³, które
produkuj¹ zbiory regu³ bez drzew decyzyjnych.

% The primary output of a decision tree algorithm is the tree itself. The 
% training process that creates the decision tree is usually called induction. 
% Induction requires a small number of passes (generally far fewer than 100) 
% through the training dataset. This makes the algorithm somewhat less efficient 
% than Naýve-Bayes algorithms (See Naýve-Bayes and Nearest Neighbor.), which 
% require only one pass, but significantly more efficient than neural nets, which 
% typically require a large number of passes, sometimes numbering in the 
% thousands. To be more precise, the number of passes required to build a 
% decision tree is no more than the number of levels in the tree. There is no 
% predetermined limit to the number of levels, although the complexity of the 
% tree as measured by the depth and breadth of the tree generally increases as 
% the number of independent variables increases.

G³ówny rezultatem algorytmu drzew decyzyjnych jest w³aœnie drzewo. Proces
treningu, który tworzy drzewo, jest zwyczajowy nazywany indukcj¹. Indukcja wymaga kilku
przejœæ (generalnie znacznie mniej ni¿ 100) przez zbiór trenuj¹cy.
Powoduje to, ¿e algorytmy te s¹ mniej wydajne ni¿ algorytmy 
\emph{Naýve-Bayes}, które wymagaj¹ tylko jednego przejœcia, ale znacznie bardziej wydajne
ni¿ sieci neuronowe, które zazwyczaj wymagaj¹ wielkiej iloœci przejœæ, czasami
liczonych w tysi¹cach. Dok³adniej iloœæ potrzebnych przejœæ wymaganych do
zbudowania drzewa decyzyjnego jest nie wiêksza ni¿ wysokoœæ drzewa (iloœæ
warstw). Nie istnieje okreœlona z góry maksymalna wysokoœæ drzewa, jednak¿e
z³o¿onoœæ drzewa mierzona jako jego wysokoœæ i szerokoœæ generalnie roœnie jeœli
roœnie iloœæ niezale¿nych zmiennych.


%\usepackage{graphics} is needed for \includegraphics
\begin{figure}[htp]
\begin{center}
  \includegraphics[width=0.3\textwidth]{img/sample_tree.jpg}
  \caption[labelInTOC]{Drzewo decyzyjne}
  \label{fig:sample_tree}
\end{center}
\end{figure}
