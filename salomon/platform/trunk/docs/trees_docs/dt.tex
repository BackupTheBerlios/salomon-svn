\documentclass[a4paper, 12pt]{article}
%\usepackage[polish]{babel}
%\usepackage[cp1250]{inputenc}
\usepackage[latin2]{inputenc}
%\usepackage{polski}
\usepackage[T1]{fontenc}
\usepackage{graphicx}


\pagestyle{headings}
\textwidth      15.5cm
\oddsidemargin    .1cm
\evensidemargin   .1cm



\begin{document}

\thispagestyle{empty}

\begin{minipage}{5cm}
%\includegraphics[scale=0.3]{logo.eps}
\end{minipage}
\begin{minipage}{10cm}
\begin{center}
{Salomon\\
System przetwarzania wiedzy\\}
\end{center}
\end{minipage}

\vspace*{0.5cm}

\hrulefill

\vspace*{1cm}


\begin{flushleft}

\section{Drzewa decyzyjne w teorii decyzji}

W teorii decyzji drzewo decyzyjne jest drzewem decyzji i ich mozliwych konsekwencji (stanów natury). Zadaniem drzew decyzyjnych mo¿e byæ zarówno stworzenie planu, jak i rozwiazanie problemu decyzyjnego.

Metoda drzew decyzyjnych jest szczególnie przydatna w problemach decyzyjnych z licznymi, rozga³eziajacymi sie wariantami oraz w przypadku podejmowania decyzji w warunkach ryzyka.

\section{Drzewa decyzyjne w uczeniu maszynowym}

Drzewa decyzyjne w uczeniu maszynowym s³uzy do wyodrebniania wiedzy z zestawu przyk³adów (patrz eksploracja danych). Zak³adamy, ze posiadamy zestaw przyk³adów: obiektów opisanych przy pomocy atrybutów, którym przyporzadkowujemy jakas decyzje (patrz tabela decyzyjna).

Przyk³ad: Chcemy zautomatyzowaæ proces przyjmowania kandydatów na praktyki w duzej firmie. Posiadamy setki przyk³adów z przesz³osci, chcemy wydobyæ z nich regu³y decyzyjne. Atrybuty Wykszta³cenie, Jezyki obce, Doswiadczenie i Ogólne wrazenie sa kodowane skala od 1 do 5.
\linebreak
%do poprawy
\begin{table}[h]
%\multicolumn{7}{c}{	}
Wiek 	P³eæ 	Wykszta³cenie 	Jezyki 	Doswiadczenie 	Prezentacja 	Przyjety\linebreak 
25 	m 	2 	4 	1 	4 	nie\linebreak 
22 	k 	4 	3 	4 	2 	nie\linebreak 
21 	m 	4 	5 	5 	4 	tak\linebreak 
29 	m 	1 	3 	2 	3 	nie\linebreak 
\caption{}
\end{table} 
\linebreak
Na podstawie tabeli decyzyjnej tworzymy drzewo, którego wez³ami sa poszczególne atrybuty, ga³eziami wartosci odpowiadajace tym atrybutom, a liscie tworza poszczególne decyzje. Na podstawie przyk³adowych danych wygenerowano nastepujace drzewo:

	\begin{center}
	\includegraphics[bb=0 447 441 842]{dd.eps}
% dd.eps: 300dpi, width=3.73cm, height=3.34cm, bb=0 447 441 842
	\end{center}

Drzewo w takiej postaci odzwierciedla w jaki sposób by³y na podstawie atrybutów by³y podejmowane decyzje klasyfikujace (dla uproszczenia po³aczono niektóre ga³ezie). Zaleta tej reprezentacji jest jej czytelnosæ dla cz³owieka. W prosty sposób mozna przekszta³ciæ ja do reprezentacji regu³owej.

\section{Algorytm tworzenia drzewa ID3}
\subsection{Wstep}
Algorytm tworzenia drzew decyzyjnych ID3 jest jednym z prostszych algorytmow ale zarazem daje on dosc dobre wyniki. Celem jest oczywiscie stworzenie drzewa, ktore za pomoca wartosci atrybutow przyjmowanych przez elementy podzieli nam dziedzine na klasy rownowaznosci (w domysle podgrupy majace taka sama wartosc jednej ze zmiennych). Oczywiscie w typowym przypadku mozliwosci stworzenia takiego drzewa bedzie wiele. Wiec ustalamy dodatkowy cel, jakim bedzie minimalna wysokosc drzewa, liczona jako najwieksza odleglosc od korzenia do liscia. Algorytm ID3 zawsze (jezeli to mozliwe) stworzy nam drzewo decyzyjne. Natomiast nie zawsze jest to drzewo optymalnej wielkosci. Algorytm jest ID3 jest algorytmem zachlannym, decyzje o rozbudowie drzewa sa podejmowane na podstawie przyblizonej oceny kazdego z wariantow jakie mozemy przyjac w danym kroku. Raz podjeta decyzja nie jest juz zmieniana - nie jest to algorytm adaptatywny. Przyjrzyjmy sie jego dzialaniu.

\subsection{W duzym skrocie}

Dopuki kazdy z lisci drzewa nie jest homogeniczny (zmienne decyzyjne jego elementow nie sa jednakowe) powtarzaj:

    \begin{itemize}
\item Wybierz ten sposrod nieuzytych jeszcze atrybutow, ktory minimalizuje srednia entropie (opis sredniej entropii dalej)
\item Rozwin niehomogeniczne liscie wzgledem wybranego atrybutu.
\end{itemize}


\subsection{Formula Entropii}

Entropia jest miara z teorii informacji, charakteryzujaca czystosc i homogenicznosc zbioru atrybutow. 

\subsubsection{Dane}
\begin{itemize}
\item nb, liczba instancji w lisciu b
\item nbc, liczba instancji w lisciu b nalezacych do klasy c. nbc <= nb
\item nt, calkowita liczna instancji we wszystkich lisciach
\end{itemize}

\subsubsection{Prawdopodobienstwo}
$P_{b}=\frac{n_{bc}}{n_{b}}$
\begin{itemize}
\item Jezeli wszystkie instancje w grupie sa klasyfikowane pozytywnie, wtedy Pb = 1 (lisc homogeniczny pozytywnie) 
\item Jezeli wszystkie instancje w grupie sa klasyfikowane negatywnie, wtedy Pb = 0 (lisc homogeniczny negatywnie) 
\end{itemize}


\subsubsection{Entropia}
$Entropia = Sum(c)(-\frac{n_{bc}}{n_{b}})log_{2}(\frac{n_{bc}}{n_{b}})$

\begin{itemize}
\item Entropia jest zerowa jezeli zbior jest idealnie homogeniczny
\item Entropie wynosi 1 jezeli zbior jest idealnie niehomogeniczny ze wzgledu na atrybut (tzn. nie jest on dzielony na zadne podgrupy przez ten atrybut)
\end{itemize}

\subsubsection{Srednia entropia}
$Srednia entropia = Sum(b)(\frac{n_{b}}{n_{t}})*[Sum(c)(-\frac{n_{bc}}{n_{b}})log_{2}(\frac{n_{bc}}{n_{b}})]$


\subsection{Minimalizacja entropii = Minimalizacja wysokosci drzewa ???}

Ogolne zalozenie jest aby tworzyc drzewa decyzyjne optymalnej wielkosci ale z praktycznego punktu widzenia nie jest to uzasadnione ze wzgledu na duzy koszt obliczeniowy. W zastepstwie korzystamy z przyblizonych procedur tworzenia malych, ale niekoniecznie najmniejszych drzew decyzyjnych.

\subsection{Algorytm w pseudokodzie}
\begin{enumerate}
\item Zainicjuj drzewo (wszystkie elementy przypisane do korzenia, ktory jest zarazem lisciem)
\item Dopuki nie wszystkie liscie sa homogeniczne powtarzaj
\subitem - Jezeli nie ma nieuzytych atrybutow -> \textbf{koniec z bledem}
\subitem - Oblicz srednia entropie dla nieuzytych jeszcze atrybutow
\subitem - Wybierz ten atrybut, ktory minimalizuje srednia entropie (dla ktorego wyliczony w poprzednim punkcie wskaznik jest najmniejszy)
\subitem - Rozwijaj niehomogeniczne liscie wzgledem wybranego atrybutu (lisc staje sie wezlem, do ktorego sa "przyczepione" liscie powstale z podzialu tego liscia na liscie zawierajace kazda z przyjmowanych przez wybrany atrybut wartosci)
\item Wypisz drzewo -> \textbf{poprawny koniec}

\end{enumerate}
\subsection{Podsumowanie}
Algorytm ID3 jest prostym algorytmem pozwalajacym na generowanie poprawnych drzew decyzyjnych. Jego podstawowa forma, opisana powyzej umozliwia 

\end{flushleft}
\end{document}
